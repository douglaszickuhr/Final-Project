---
title: "Clustering companies by consumer complaints"
author: "Douglas Zickuhr"
date: "21/06/2018"
output:
  html_document: default
  pdf_document: default
---

# Loading libraries
```{r libraries}
library(tidyverse)
library(e1071)
library(cluster)

```

## Loading the dataset
```{r reading}
df <- read_csv('data/dataset.csv')
```

## Checking the dataframe
```{r check data}
head(df)
glimpse(df)
```

## Aggregating the dataset to create indicators by company.
It's important to mention that just companies with more the 50 complaints and at least 5 solved complaints were considered.
```{r df_aggregation}
set.seed(123)
companies <- df %>%
  dplyr::filter(!is.na(company_name)) %>%
  dplyr::mutate(company_name = str_replace_all(company_name,"'","")) %>%
  dplyr::mutate(company_name = str_replace_all(company_name,'"',"")) %>%
  dplyr::mutate(company_name = str_trim(company_name)) %>%
  dplyr::mutate(average_weeks = difftime(complaint_closed_date,
                                  complaint_entered_date,
                                  units="weeks")) %>%
  dplyr::group_by(company_name) %>%
  dplyr::summarise(total_complaint = n(),
            total_solved_complaint = sum(complaint_attended == "Y"),
            perc_solved = total_solved_complaint/total_complaint,
            average_weeks = as.numeric(round(mean(average_weeks),digits = 2))
            ) %>%
  dplyr::filter(total_complaint > 50) %>%
  dplyr::filter(total_solved_complaint > 5) %>%
  dplyr::select(-c("total_solved_complaint")) %>%
  dplyr::mutate(company_id = row_number())
```

## Scalling companies's indicators
```{r scalling}
companies_scalled <- companies %>%
  dplyr::select(-c("company_name","company_id")) %>%
  scale(center = TRUE,
        scale = TRUE)

```


## PCA - Principal component analysis

PCA is a algorithm to apply reduction of dimensions
```{r pca}
companies_pca <- prcomp(companies_scalled, 
                        scale. = FALSE)
```

Looking to the summary of the PCA it's possible to see that with PC2 it's possible to explain more than 70% of data variance
```{r pca_summary}
summary(companies_pca)
```

# Clustering

## Binding the companies data frame and principal components 
```{r companies_pca_binding}
companies_with_pca <- cbind(companies,
                   companies_pca$x)
```


## K-means 
### Running silhouette analysis to find the best number of clustering
```{r kmeans_silhoette_analysis}
companies_silhouette_vector <- numeric(9)
k_var <- 2:10
nstart = 20

for (k in k_var){
  set.seed(123)
  companies_kmeans <- kmeans(companies_with_pca %>%
                               select(starts_with("PC")),
                             centers = k,
                             nstart = nstart,
                             iter.max = 300)
  
  
  companies_kmeans_distance <- companies_with_pca %>%
    select(starts_with("PC")) %>%
    dist()
  
  s <- silhouette(companies_kmeans$cluster,companies_kmeans_distance)
  
  companies_silhouette_vector[k-1] <- mean(s[,3])
}


silhouette_analysis <- tibble(
  clusters = k_var,
  s = companies_silhouette_vector
) %>%
  arrange(desc(s))

silhouette_analysis
```

### Running Kmeans with the best result from silhouette analysis
```{r kmeans}
k = 5
set.seed(123)
companies_kmeans <- kmeans(companies_with_pca %>%
                  select(starts_with("PC")),
                centers = k,
                nstart = nstart,
                iter.max = 300)
```


## Fuzzy Clustering
```{r fcm}
k = 5
set.seed(123)
companies_fcm <- cmeans(companies_with_pca %>%
                                 select(starts_with("PC")),
                        centers = k,
                        iter.max = 300,
                        verbose = TRUE)
```

## Evaluation of values by clusters (Kmeans and Fuzzy Clusters)
### Binding the clusters into a single tibble
```{r binding clusters to dataframe}
companies_membership_degree <- companies_with_pca %>%
  cbind(companies_fcm$membership) %>%
  dplyr::rename("fuzzy_cluster_1" = `1`,
                "fuzzy_cluster_2" = `2`,
                "fuzzy_cluster_3" = `3`,
                "fuzzy_cluster_4" = `4`,
                "fuzzy_cluster_5" = `5`)

companies_membership_degree <- companies_membership_degree %>%
  dplyr::select(company_name,starts_with("fuzzy_cluster_")) %>%
  gather(degree,membership_degree,-company_name) %>%
  group_by(company_name) %>%
  dplyr::summarise(fuzzy_membership_degree = max(membership_degree))

companies_clusters <- companies_with_pca %>%
  cbind(kmeans_cluster = companies_kmeans$cluster) %>%
  cbind(fuzzy_cluster = companies_fcm$cluster) %>%
  inner_join(companies_membership_degree)

write_csv(x = companies_clusters, path = "data/clustered_companies.csv")
```

### Plotting the data based on Kmeans clusters
```{r kmeans scatter plot}
ggplot(companies_with_pca) + 
  geom_point(aes(PC1,
                 PC2,
                 colour=factor(companies_kmeans$cluster))) + 
  labs(colour = "Cluster",
       title = "K-means Clustering")
```

### Average values by Kmeans Clusters
```{r average values for kmeans}
companies_clusters %>%
  dplyr::group_by(kmeans_cluster) %>%
  dplyr::summarise(total_complaint = mean(total_complaint),
                   perc_solved = mean(perc_solved),
                   average_weeks = mean(average_weeks),
                   n = n()) %>%
  dplyr::select(c(kmeans_cluster,total_complaint,perc_solved,average_weeks,n))
```


### Plotting the data based on fuzzy clusters
```{r}
ggplot(companies_clusters) + 
  geom_point(aes(PC1,
                 PC2,
                 colour = factor(fuzzy_cluster))) +
  labs(colour = "Cluster",
       title = "Fuzzy Clustering") + 
  scale_alpha_continuous(guide = FALSE)
  
```

### Average values by Fuzzy Clusters
```{r average values for hclust}
companies_clusters %>%
  dplyr::group_by(fuzzy_cluster) %>%
  dplyr::summarise(total_complaint = mean(total_complaint),
                   perc_solved = mean(perc_solved),
                   average_weeks = mean(average_weeks),
                   n = n()) %>%
  dplyr::select(c(fuzzy_cluster,total_complaint,perc_solved,average_weeks,n))
```

